<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>Diffusion学习3-代码实践</title><meta name="description" content="The harder you work, the luckier you will be~"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="先放一张在人脸数据集上训练好后去噪的可视化过程

DDPM可视化去噪

各数据集参数配置及效果
训练:
CUDA_VISIBLE_DEVICES=0 python train_solver.py --data_name &quot;Flower102&quot;
在config.yaml中各个数据集使用默认的Training Setting，每个数据集特有的配置见config.yaml下的Train_Data.
生成效果
生成效果如下:



数据集
去噪过程可视化
最终去噪效果
插值




Mnist





Fashion_Mnist





Cifar10





Flower102





StyleGAN2人脸






上述训练数据集和已经训练好的模型放在这里.

去噪过程可视化中，如果在采样step内.."><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Georgeqi_Blog" type="application/atom+xml">
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Georgeqi's Blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Diffusion学习3-代码实践</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E5%8F%8A%E6%95%88%E6%9E%9C"><span class="toc-text">各数据集参数配置及效果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E6%95%88%E6%9E%9C"><span class="toc-text">生成效果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AEcode"><span class="toc-text">参考文献&#x2F;Code</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/Diffusion"><i class="tag post-item-tag">Diffusion</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">Diffusion学习3-代码实践</h1><time class="has-text-grey" datetime="2022-12-25T13:27:59.000Z">2022-12-25</time><article class="mt-2 post-content"><p>先放一张在人脸数据集上训练好后去噪的可视化过程</p>
<figure>
<img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221228191848_StyleGAN_face_size128_225_progress.jpg" alt="DDPM可视化去噪"><figcaption aria-hidden="true">DDPM可视化去噪</figcaption>
</figure>
<h2 id="各数据集参数配置及效果">各数据集参数配置及效果</h2>
<p>训练:</p>
<pre><code>CUDA_VISIBLE_DEVICES=0 python train_solver.py --data_name "Flower102"</code></pre>
<p>在config.yaml中各个数据集使用默认的Training Setting，每个数据集特有的配置见config.yaml下的Train_Data.</p>
<h2 id="生成效果">生成效果</h2>
<p>生成效果如下:</p>
<table>
<thead>
<tr class="header">
<th>数据集</th>
<th>去噪过程可视化</th>
<th>最终去噪效果</th>
<th>插值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mnist</td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221225095139_mnist_latest_progress.jpg"></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221225095139_mnist_latest_final.jpg"></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221226174548_mnist_latest_interpolate.jpg"></td>
</tr>
<tr class="even">
<td>Fashion_Mnist</td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221225200037_fashion_mnist_latest_progress.jpg"></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221225200037_fashion_mnist_latest_final.jpg"></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221226175012_fashion_mnist_latest_interpolate.jpg"></td>
</tr>
<tr class="odd">
<td>Cifar10</td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221225200604_cifar10_latest_progress.jpg"></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221225200604_cifar10_latest_final.jpg"></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221226174822_cifar10_latest_interpolate.jpg"></td>
</tr>
<tr class="even">
<td><a target="_blank" rel="noopener" href="https://www.robots.ox.ac.uk/~vgg/data/flowers/102/">Flower102</a></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221226111542_flower102_size64_progress.jpg"></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221226111542_flower102_size64_final.jpg"></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221226173958_flower102_size64_858_interpolate.jpg"></td>
</tr>
<tr class="odd">
<td>StyleGAN2人脸</td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221226130201_StyleGAN_face_size128_progress.jpg"></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221226130201_StyleGAN_face_size128_final.jpg"></td>
<td><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221226174754_StyleGAN_face_size128_225_interpolate.jpg"></td>
</tr>
</tbody>
</table>
<p>上述训练数据集和已经训练好的模型放在<a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/1yInbcK5pq9qMhkl9ES3QIZr69LXkeeQK">这里</a>.</p>
<ul>
<li><p>去噪过程可视化中，如果在采样step内均匀采样时间戳，会发现前面的去噪过程过于缓慢而后面会突然“有效果”，所以这里对于时间戳采用了一个“先粗后细”的采样trick用于可视化。</p></li>
<li><p>上述插值方法由<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.11239.pdf">原DDPM</a> 论文中提出，本仓库采用其默认配置: <code>扩散步数=500，插值系数从0~1均匀采样11次</code> 其中第一行和最后一行分别为两个原始的插值图片，中间11行为插值的结果，并且第二行和倒数第二行插值系数分别为0和1，可以看成是对原始两个插值图片的重构。 实验下来：感觉插值的结果并非是平缓的，而是中间会有一个比较“陡峭”的突变过程.....和<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.11239.pdf">DDPM</a> 原文中的Figure.8产生的图片接近，暂时没找到这种突变的合理解释~</p></li>
</ul>
<p>完整代码见: <a target="_blank" rel="noopener" href="https://github.com/qzq2514/Diffusion">qzq2514/Diffusion</a></p>
<h2 id="参考文献code">参考文献/Code</h2>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.11239.pdf">DDPM</a><br>
<a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v139/nichol21a/nichol21a.pdf">Improved DDPM</a><br>
<a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What are Diffusion Models</a><br>
<a target="_blank" rel="noopener" href="https://github.com/lucidrains/denoising-diffusion-pytorch">lucidrains/denoising-diffusion-pytorch</a><br>
<a target="_blank" rel="noopener" href="https://github.com/zoubohao/DenoisingDiffusionProbabilityModel-ddpm-">zoubohao/DenoisingDiffusionProbabilityModel-ddpm</a><br>
<a target="_blank" rel="noopener" href="https://github.com/LianShuaiLong/CV_Applications">LianShuaiLong/CV_Applications</a><br>
<a target="_blank" rel="noopener" href="https://github.com/yiyixuxu/denoising-diffusion-flax">yiyixuxu/denoising-diffusion-flax</a></p>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2022/12/31/Diffusion%E5%AD%A6%E4%B9%A04-%E6%95%88%E6%9E%9C%E5%92%8C%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87/" title="Diffusion学习4-效果和性能提升"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">Previous: Diffusion学习4-效果和性能提升</span></a><a class="button is-default" href="/2022/12/20/Diffusion%E5%AD%A6%E4%B9%A02-%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC/" title="Diffusion学习2-理论推导"><span class="has-text-weight-semibold">Next: Diffusion学习2-理论推导</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="qzq2514/qzq2514.github.io" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com/qzq2514"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/qzq2514"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com/qzq2514"><i class="iconfont icon-ins"></i></a><!-- publish--><a title="publish" target="_blank" rel="noopener nofollow" href="https://blog.csdn.net/qzq2514"><i class="iconfont icon-rss"></i></a><!-- RSS--><!-- 知乎--><a title="zhihu" target="_blank" rel="noopener nofollow" href="//zhihu.com/people/qi-zhong-qi-62"><i class="iconfont icon-zhihu"></i></a><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> Georgeqi 2023</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>