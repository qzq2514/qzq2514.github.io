<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>Pytorch-Hookæœºåˆ¶</title><meta name="description" content="The harder you work, the luckier you will be~"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="Hookæ˜¯ä»€ä¹ˆï¼Ÿ
Hook(é’©å­)å…¶å®å¹¶ä¸æ˜¯Pytorchç‰¹æœ‰çš„æœºåˆ¶ï¼Œå…¶åœ¨è½¯ä»¶å·¥ç¨‹ä¸­ä¹Ÿæ˜¯ç›¸å½“å¸¸è§çš„ï¼Œä¸€èˆ¬æ¥è¯´Hookè¡¨ç¤ºä¸€ç§è‡ªåŠ¨è§¦å‘çš„æœºåˆ¶ï¼Œå³åœ¨é‡åˆ°æŸäº›æ—¶é—´/æƒ…å†µä¹‹åä¼šè‡ªåŠ¨æ‰§è¡Œçš„äº‹é¡¹ï¼Œå…¶å®åœ¨ç”Ÿæ´»ä¸­ä¹Ÿä¼šé‡åˆ°å¾ˆå¤šHookçš„äº‹ä»¶ï¼š

ç§»åŠ¨åˆ°å…‰çº¿å˜åŒ–çš„ç¯å¢ƒé‡Œï¼Œæ‰‹æœºå±å¹•äº®åº¦ä¼šè·Ÿç€å˜åŒ–
æ°´çƒ§å¼€åå°±ä¼šæ²¸è…¾æŠŠå£¶ç›–é¡¶å¼€
ç«ç¾æƒ…å†µä¸‹æ¸©åº¦å‡é«˜è‡ªåŠ¨è§¦å‘æŠ¥è­¦ç³»ç»Ÿå’Œç­ç«å–·å¤´

æ€»è€Œè¨€ä¹‹ï¼Œè™½ç„¶ä¸Šé¢å¾ˆå¤šæƒ…å†µå³ä¾¿æ²¡æœ‰Hookï¼Œæˆ‘ä»¬ä¹Ÿèƒ½å®ç°(æ¯”å¦‚æ‰‹åŠ¨è°ƒäº®åº¦ã€æ‰‹åŠ¨æ‰“å¼€æŠ¥è­¦å’Œç­ç«å™¨ç­‰)ï¼Œä½†æ˜¯Hookä½œä¸ºä¸€ç§å¼ºå¤§çš„è‡ªåŠ¨è§¦å‘æœºåˆ¶ï¼Œèƒ½å¤Ÿå¾ˆå¤§ç¨‹åº¦ä¸Šå¸®åŠ©æˆ‘ä»¬æé«˜æ•ˆç‡ã€‚
Pytorchä¸­çš„
Hookæ˜¯å¹²å˜›çš„ï¼Ÿ
å½“æƒ³è¦æŸ¥çœ‹ç½‘ç»œè¾“å‡ºä¸­æ¯å±‚ç‰¹å¾çš„shapeæ—¶ï¼Œæœ‰æ²¡æœ‰è¿‡æ‰‹åŠ¨printæ¯ä¸ªtensor.shapeçš„æƒ…å†µï¼Ÿè™½ç„¶å¿«ä½†æ˜¯ä¸â€œä¼˜é›…â€è€Œä¸”å¾ˆæœ‰å¯èƒ½å¯¼è‡´ä»£ç æ˜¾å¾—å†—ä½™.."><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Georgeqi_Blog" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Georgeqi's Blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Pytorch-Hookæœºåˆ¶</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#hook%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">Hookæ˜¯ä»€ä¹ˆï¼Ÿ</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch%E4%B8%AD%E7%9A%84-hook%E6%98%AF%E5%B9%B2%E5%98%9B%E7%9A%84"><span class="toc-text">Pytorchä¸­çš„
Hookæ˜¯å¹²å˜›çš„ï¼Ÿ</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch%E4%B8%ADhook%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-text">Pytorchä¸­Hookçš„åº”ç”¨</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%93%E5%8D%B0%E4%B8%AD%E9%97%B4%E5%BC%A0%E9%87%8F%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="toc-text">1.æ‰“å°ä¸­é—´å¼ é‡çš„ä¿¡æ¯</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81"><span class="toc-text">2.æå–ç‰¹å¾</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E8%A3%81%E5%89%AA1"><span class="toc-text">3.æ¢¯åº¦è£å‰ª1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E8%A3%81%E5%89%AA2"><span class="toc-text">3.æ¢¯åº¦è£å‰ª2</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">æ€»ç»“</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80"><i class="tag post-item-tag">ç¼–ç¨‹è¯­è¨€</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">Pytorch-Hookæœºåˆ¶</h1><time class="has-text-grey" datetime="2023-08-10T08:01:50.000Z">2023-08-10</time><article class="mt-2 post-content"><h1 id="hookæ˜¯ä»€ä¹ˆ">Hookæ˜¯ä»€ä¹ˆï¼Ÿ</h1>
<p>Hook(é’©å­)å…¶å®å¹¶ä¸æ˜¯Pytorchç‰¹æœ‰çš„æœºåˆ¶ï¼Œå…¶åœ¨è½¯ä»¶å·¥ç¨‹ä¸­ä¹Ÿæ˜¯ç›¸å½“å¸¸è§çš„ï¼Œä¸€èˆ¬æ¥è¯´Hookè¡¨ç¤ºä¸€ç§è‡ªåŠ¨è§¦å‘çš„æœºåˆ¶ï¼Œå³åœ¨é‡åˆ°æŸäº›æ—¶é—´/æƒ…å†µä¹‹åä¼šè‡ªåŠ¨æ‰§è¡Œçš„äº‹é¡¹ï¼Œå…¶å®åœ¨ç”Ÿæ´»ä¸­ä¹Ÿä¼šé‡åˆ°å¾ˆå¤šHookçš„äº‹ä»¶ï¼š</p>
<ul>
<li>ç§»åŠ¨åˆ°å…‰çº¿å˜åŒ–çš„ç¯å¢ƒé‡Œï¼Œæ‰‹æœºå±å¹•äº®åº¦ä¼šè·Ÿç€å˜åŒ–</li>
<li>æ°´çƒ§å¼€åå°±ä¼šæ²¸è…¾æŠŠå£¶ç›–é¡¶å¼€</li>
<li>ç«ç¾æƒ…å†µä¸‹æ¸©åº¦å‡é«˜è‡ªåŠ¨è§¦å‘æŠ¥è­¦ç³»ç»Ÿå’Œç­ç«å–·å¤´</li>
</ul>
<p>æ€»è€Œè¨€ä¹‹ï¼Œè™½ç„¶ä¸Šé¢å¾ˆå¤šæƒ…å†µå³ä¾¿æ²¡æœ‰Hookï¼Œæˆ‘ä»¬ä¹Ÿèƒ½å®ç°(æ¯”å¦‚æ‰‹åŠ¨è°ƒäº®åº¦ã€æ‰‹åŠ¨æ‰“å¼€æŠ¥è­¦å’Œç­ç«å™¨ç­‰)ï¼Œä½†æ˜¯Hookä½œä¸ºä¸€ç§å¼ºå¤§çš„è‡ªåŠ¨è§¦å‘æœºåˆ¶ï¼Œèƒ½å¤Ÿå¾ˆå¤§ç¨‹åº¦ä¸Šå¸®åŠ©æˆ‘ä»¬æé«˜æ•ˆç‡ã€‚</p>
<h1 id="pytorchä¸­çš„-hookæ˜¯å¹²å˜›çš„"><strong>Pytorchä¸­çš„
Hookæ˜¯å¹²å˜›çš„ï¼Ÿ</strong></h1>
<p>å½“æƒ³è¦æŸ¥çœ‹ç½‘ç»œè¾“å‡ºä¸­æ¯å±‚ç‰¹å¾çš„shapeæ—¶ï¼Œæœ‰æ²¡æœ‰è¿‡æ‰‹åŠ¨printæ¯ä¸ª<code>tensor.shape</code>çš„æƒ…å†µï¼Ÿè™½ç„¶å¿«ä½†æ˜¯ä¸â€œä¼˜é›…â€è€Œä¸”å¾ˆæœ‰å¯èƒ½å¯¼è‡´ä»£ç æ˜¾å¾—å†—ä½™æ‚ä¹±ã€‚è¿™æ—¶å€™å¦‚æœåœ¨ç½‘ç»œå‰å‘è¿‡ç¨‹ä¸­è®¾ç½®hookæœºåˆ¶ï¼Œå°±èƒ½è‡ªåŠ¨æ‰“å°å¼ é‡çš„shapeï¼Œå¹¶ä¸”ä¸ä¼šå½±å“åŸä»£ç çš„åŠŸèƒ½å’Œé€»è¾‘ï¼Œè¿™äº›è¢«æ·»åŠ çš„å°åŠŸèƒ½å°±åƒä¸€ä¸ªå°é’©å­ğŸªä¸€æ ·â€œæŒ‚â€åœ¨åŸä»£ç é€»è¾‘ä¸Šä½†æ˜¯ä¸ä¼šæ”¹å˜åŸé€»è¾‘ã€‚</p>
<p>åœ¨Pytorchä¸­Hookèƒ½åšçš„äº‹æƒ…éå¸¸å¤šï¼š</p>
<ul>
<li>æ‰“å°è¾“å‡ºæ¯å±‚å¼ é‡çš„shape</li>
<li>æŸ¥çœ‹æˆ–ä¿®æ”¹æ¯å±‚å‚æ•°çš„æ¢¯åº¦(æ¯”å¦‚è¿›è¡Œæ¢¯åº¦è£å‰ª)</li>
<li>å¯è§†åŒ–ç½‘ç»œä¸­é—´å±‚çš„ç‰¹å¾å›¾</li>
<li>â€¦.</li>
</ul>
<p>åœ¨Pytorchä¸­å¸¸ç”¨çš„å¯ä»¥ç»™å¼ é‡(Tensor)æˆ–è€…æ¨¡å‹(Module)è®¾ç½®Hook:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html?highlight=hook">torch.Tensor.register_hook</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_hook">torch.nn.Module.register_forward_hook</a>ï¼šåœ¨å‰å‘æ¨ç†æ—¶æ‰§è¡Œ</li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_backward_hook">torch.nn.Module.register_backward_hook</a></li>
</ul>
<p>é’ˆå¯¹Tensorå’ŒModuleçš„hookå‡½æ•°ç­¾åå¦‚ä¸‹:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn, Tensor</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> module_hook(module:nn.Module, <span class="bu">input</span>:Tensor, output:Tensor):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æ¥å—moduleç±»å‹å¯¹è±¡ï¼ŒåŠå…¶è¾“å…¥è¾“å‡ºï¼Œè¿™é‡Œå¯ä»¥åšå°ºå¯¸çš„æ‰“å°ã€æ¢¯åº¦è£å‰ªã€ç‰¹å¾æå–ç­‰</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tensor_hook(grad:Tensor):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æ¥å—tensorçš„æ¢¯åº¦ä¿¡æ¯ï¼Œè¿™é‡Œä¹Ÿå¯ä»¥åšå°ºå¯¸çš„æ‰“å°ã€æ¢¯åº¦è£å‰ª</span></span></code></pre></div>
<h1 id="pytorchä¸­hookçš„åº”ç”¨">Pytorchä¸­Hookçš„åº”ç”¨</h1>
<h2 id="æ‰“å°ä¸­é—´å¼ é‡çš„ä¿¡æ¯">1.æ‰“å°ä¸­é—´å¼ é‡çš„ä¿¡æ¯</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn, Tensor</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DemoMoudule(nn.Module):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ„å»ºä¸€ä¸ªç®€å•çš„DNNç½‘ç»œ: ç”±ä¸¤ä¸ªå·ç§¯è¾“å…¥å±‚ã€ä¸€ä¸ªBNå±‚ã€ä¸€ä¸ªå·ç§¯è¾“å‡ºå±‚</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_in <span class="op">=</span> nn.Sequential(nn.Conv2d(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>                                      nn.Conv2d(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>))</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn <span class="op">=</span> nn.BatchNorm2d(<span class="dv">1</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_out <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">20</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä¸ºè¯¥ç½‘ç»œçš„æ¯ä¸ªä¸€çº§å­module(å³conv_inã€bnå’Œconv_out)æ³¨å†Œå‰å‘hook,</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åœ¨forwardæ—¶å€™ä¼šè‡ªåŠ¨è°ƒç”¨å¯¹åº”çš„å‡½æ•°(è¿™é‡Œæ˜¯æ‰“å°è¯¥moduleè¾“å‡ºå±‚çš„åç§°ã€å°ºå¯¸ã€å‡å€¼)</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, layer <span class="kw">in</span> <span class="va">self</span>.named_children():</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>            layer.<span class="va">__name__</span> <span class="op">=</span> name</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>            layer.register_forward_hook(</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>                <span class="kw">lambda</span> l, _, output:</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">"</span><span class="sc">{}</span><span class="st">:</span><span class="sc">{}</span><span class="st">,</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(l.<span class="va">__name__</span>, output.shape, torch.mean(output)))</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: Tensor) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv_in(x)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.bn(x)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv_out(x)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>demo_model <span class="op">=</span> DemoMoudule()</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>dummy_input <span class="op">=</span> torch.ones(<span class="dv">10</span>, <span class="dv">3</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>dummy_output <span class="op">=</span> demo_model(dummy_input)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co">è¾“å‡ºï¼š</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co">conv_in:torch.Size([10, 1, 6, 6]),-0.3441038727760315</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="co">bn:torch.Size([10, 1, 6, 6]),0.0</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="co">conv_out:torch.Size([10, 20, 4, 4]),0.07038399577140808</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span></code></pre></div>
<p>åˆ©ç”¨æ­¤æŠ€æœ¯ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é’ˆå¯¹å·²æœ‰çš„ç½‘ç»œï¼ˆæ¯”å¦‚ResNet50ï¼‰,åœ¨ä¸ä¿®æ”¹è¯¥ç½‘ç»œå®šä¹‰å’Œæºç çš„åŒæ—¶ä½¿ç”¨ç±»ä¼¼ä¸Šé¢çš„ä¸€ä¸ªå°è£…ï¼Œåœ¨å‰å‘è¿‡ç¨‹ä¸­æ‰“å°å¯¹åº”çš„å¼ é‡å°ºå¯¸(å¯å‚è€ƒ<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/279903361">zhihu.McGL</a>)ã€‚</p>
<h2 id="æå–ç‰¹å¾">2.æå–ç‰¹å¾</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn, Tensor</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Iterable, Dict</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FeatureExtreactor(nn.Module):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model: nn.Module, layer_names:Iterable[<span class="bu">str</span>]):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer_names <span class="op">=</span> layer_names</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.__extraced_features <span class="op">=</span> {}</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        org_modules <span class="op">=</span> <span class="bu">dict</span>([<span class="op">*</span><span class="va">self</span>.model.named_modules()])</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer_name <span class="kw">in</span> layer_names:</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>            layer <span class="op">=</span> org_modules[layer_name]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>            layer.<span class="va">__name__</span> <span class="op">=</span> layer_name</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># å°†æŒ‡å®šåç§°çš„Moduleè¾“å‡ºæ·»åŠ åˆ°å¾…è¿”å›çš„é›†åˆä¸­</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>            layer.register_forward_hook(<span class="va">self</span>.append_features)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> append_features(<span class="va">self</span>, layer, _, output_tensor):</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.__extraced_features[layer.<span class="va">__name__</span>] <span class="op">=</span> output_tensor</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: Tensor) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Tensor]:</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>        _ <span class="op">=</span> <span class="va">self</span>.model(x)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.__extraced_features</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co"># è·å–æŒ‡å®šå±‚çš„å±æ€§</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>feature_extreactor <span class="op">=</span> FeatureExtreactor(demo_model, layer_names<span class="op">=</span>[<span class="st">"conv_in"</span>, <span class="st">"conv_out"</span>])</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>dummy_input <span class="op">=</span> torch.ones(<span class="dv">10</span>, <span class="dv">3</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>demo_features <span class="op">=</span> feature_extreactor(dummy_input)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, feature <span class="kw">in</span> demo_features.items():</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="sc">{}</span><span class="st">: </span><span class="sc">{}</span><span class="st"> </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(name, feature.shape, torch.mean(feature)))</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co">åœ¨ä½¿ç”¨ä¹‹å‰DemoMoudule()ç±»çš„æƒ…å†µä¸‹ï¼Œè¾“å‡ºï¼š</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="co">conv_in: torch.Size([10, 1, 6, 6]) 0.05633455887436867</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="co">conv_out: torch.Size([10, 20, 4, 4]) 0.04933914169669151</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span></code></pre></div>
<p>ä¸Šé¢åˆ©ç”¨Moduleçš„å‰å‘hookå¯ä»¥æ ¹æ®æŒ‡å®šçš„æ¨¡å—åè·å–ç½‘ç»œæŒ‡å®šçš„ç‰¹å¾å±‚ï¼Œæœ‰äº†è·å–çš„ç‰¹å¾å±‚ï¼Œæˆ‘ä»¬èƒ½åšçš„äº‹æƒ…å°±éå¸¸å¤šäº†ï¼Œä¸ä»…ä»…è·å–shapeã€å‡å€¼ï¼Œæ­¤å¤–ä¹Ÿèƒ½è¿›è¡Œç‰¹å¾å›¾å¯è§†åŒ–ç­‰ç­‰ã€‚</p>
<p>è€Œåœ¨æ·±åº¦å­¦ä¹ ä¸­å¸¸å¸¸ä¼šè¦æ±‚è®¡ç®—å›¾åƒçš„VGGç‰¹å¾ä¹Ÿå¯ä»¥ä½¿ç”¨è¯¥æ–¹æ³•æ¨ç†è·å¾—ã€‚</p>
<h2 id="æ¢¯åº¦è£å‰ª1">3.æ¢¯åº¦è£å‰ª1</h2>
<p>åœ¨æœªè¿›è¡Œæ¢¯åº¦è£å‰ªçš„æ—¶å€™ï¼Œæˆ‘ä»¬æ‰“å°demo_modelç½‘ç»œæœ€åä¸€ä¸ªå·ç§¯çš„å‰10ä¸ªbiaseçš„æ¢¯åº¦å¦‚ä¸‹:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>demo_model <span class="op">=</span> DemoMoudule()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>dummy_input <span class="op">=</span> torch.ones(<span class="dv">10</span>, <span class="dv">3</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> demo_model(dummy_input)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> pred.log().mean()</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(demo_model.conv_out.bias.grad)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">è¾“å‡ºï¼š</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">tensor([  0.7894,   1.0285,  -0.6203,  -0.1882,   0.6290,  -0.2002,   0.5751,</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">          0.1875,  -0.5093,   0.3338,  -1.4956,   0.2797,  -0.4018,  -0.1860,</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">        -12.1006,   0.2474,   1.7059,   0.1834,   0.3505,   0.3189])</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span></code></pre></div>
<p>åœ¨ä½¿ç”¨Tensorå½¢å¼çš„hookæœºåˆ¶æ—¶ï¼Œæˆ‘ä»¬è®¾å®šå‚æ•°çš„æ¢¯åº¦tensorçš„æ¢¯åº¦åœ¨æŸä¸ªèŒƒå›´å†…ï¼Œå¦‚ä¸‹ï¼š</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_clipper(model: nn.Module, clip_val:<span class="bu">float</span>)<span class="op">-&gt;</span> nn.Module:</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> parameter <span class="kw">in</span> model.parameters():</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å¯¹æ¢¯åº¦tensoræ·»åŠ ç”¨äºæ¢¯åº¦æˆªæ–­çš„hook</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        parameter.register_hook(<span class="kw">lambda</span> grad: grad.clamp_(<span class="op">-</span>clip_val, clip_val))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>clipped_model <span class="op">=</span> gradient_clipper(demo_model, <span class="fl">0.01</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> clipped_model(dummy_input)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> pred.log().mean()</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(clipped_model.conv_out.bias.grad)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">è¾“å‡ºï¼š</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">tensor([-0.0100, -0.0100,  0.0100, -0.0100, -0.0100, -0.0100,  0.0100, -0.0100,</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">        -0.0100, -0.0100,  0.0100, -0.0100, -0.0100,  0.0100,  0.0100,  0.0100,</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">        -0.0100,  0.0100, -0.0100, -0.0100])</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co">å¯ä»¥çœ‹åˆ°æ¢¯åº¦è¢«é™åˆ¶åˆ°-0.01~0.01ä¹‹é—´ã€‚</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span></code></pre></div>
<h2 id="æ¢¯åº¦è£å‰ª2">3.æ¢¯åº¦è£å‰ª2</h2>
<p>ä½¿ç”¨Moduelçš„register_backward_hookå‡½æ•°ä¹Ÿèƒ½è¿›è¡Œæ¢¯åº¦è£å‰ªï¼š</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_clipper2(model: nn.Module, clip_val:<span class="bu">float</span>)<span class="op">-&gt;</span> nn.Module:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># grad_inputå…ƒç»„åŒ…å«(biasçš„æ¢¯åº¦ï¼Œè¾“å…¥xçš„æ¢¯åº¦ï¼Œæƒé‡weightçš„æ¢¯åº¦)ï¼Œgrad_outputå…ƒç»„åŒ…å«è¾“å‡ºyçš„æ¢¯åº¦ã€‚</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è¿”å›çš„æ˜¯ä¿®æ”¹åçš„grad_input</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> back_hook(module, grad_input, grad_output):</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'grad_input: '</span>, grad_input)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'grad_output: '</span>, grad_output)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> grad_input[<span class="dv">0</span>].clamp(<span class="op">-</span>clip_val, clip_val), <span class="op">\</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>               grad_input[<span class="dv">1</span>].clamp(<span class="op">-</span>clip_val<span class="op">*</span><span class="dv">2</span>, clip_val<span class="op">*</span><span class="dv">2</span>), <span class="op">\</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>               grad_input[<span class="dv">2</span>].clamp(<span class="op">-</span>clip_val<span class="op">*</span><span class="dv">3</span>, clip_val<span class="op">*</span><span class="dv">3</span>),</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> moduel <span class="kw">in</span> model.modules():</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        moduel.register_backward_hook(back_hook)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># å› ä¸ºgrad_inputæ˜¯å¯¹è¾“å…¥xçš„æ¢¯åº¦ï¼Œæ‰€ä»¥è¦æ±‚xä¹Ÿæ˜¯æœ‰æ¢¯åº¦çš„ï¼Œå³è¦è®¾å®šrequires_grad=True</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="fl">1.</span>, <span class="fl">2.</span>, <span class="fl">10.</span>]], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>module <span class="op">=</span> gradient_clipper2(nn.Linear(<span class="dv">3</span>, <span class="dv">2</span>), <span class="fl">0.001</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> module(x)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>y.mean().backward()</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'module_bias: </span><span class="sc">{}</span><span class="st">, x:</span><span class="sc">{}</span><span class="st"> module_weight:</span><span class="sc">{}</span><span class="st">'</span>.</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>      <span class="bu">format</span>(module.bias.grad, x.grad, module.weight.grad))</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co">è¾“å‡º:</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co">grad_input:  (tensor([0.5000, 0.5000]), tensor([[0.2492, 0.2174, 0.0614]]),  tensor([[0.5000, 0.5000],</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="co">        [1.0000, 1.0000],</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co">        [5.0000, 5.0000]]))</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co">grad_output:  (tensor([[0.5000, 0.5000]]),)</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="co">module_bias: tensor([0.0010, 0.0010]), x:tensor([[0.0020, 0.0020, 0.0020]]) module_weight:tensor([[0.0030, 0.0030, 0.0030], [0.0030, 0.0030, 0.0030]])</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span></code></pre></div>
<h1 id="æ€»ç»“">æ€»ç»“</h1>
<p>hookæœºåˆ¶èƒ½å¤Ÿæ–¹ä¾¿å¿«æ·åœ°å¸®åŠ©æˆ‘ä»¬åšä¸€äº›è°ƒè¯•ç­‰è¾…åŠ©å·¥ä½œï¼ŒåŒæ—¶ä¹Ÿèƒ½ä¿è¯ä»£ç çš„ç®€æ´æ€§ï¼Œå…¶å®é™¤äº†ä¸Šé¢çš„ä¸‰ç§hookï¼Œpytorchè¿˜æœ‰register_full_backward_hookã€register_forward_pre_hookç­‰ï¼Œä½†æ˜¯æ¯”è¾ƒå¸¸ç”¨çš„ä¸‰ç§å’Œå¯¹åº”çš„ç”¨æ³•åˆ—åœ¨ä¸Šé¢äº†ï¼Œå…¶ä»–çš„ç”¨åˆ°æ—¶å€™å†è‡ªå·±çœ‹åè¡¥å……è¿›æ¥ï¼</p>
<p>å‚è€ƒ:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook">https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/sddai/p/14412250.html">https://www.cnblogs.com/sddai/p/14412250.html</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/279903361">https://zhuanlan.zhihu.com/p/279903361</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/winycg/article/details/100695373">https://blog.csdn.net/winycg/article/details/100695373</a></li>
</ul>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2023/10/10/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%96%B0%E8%A7%86%E8%A7%92%E7%94%9F%E6%88%90(NVS)/" title="è®ºæ–‡ç¬”è®°-æ–°è§†è§’ç”Ÿæˆ(NVS)"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">Previous: è®ºæ–‡ç¬”è®°-æ–°è§†è§’ç”Ÿæˆ(NVS)</span></a><a class="button is-default" href="/2023/06/10/Diffusion%E5%AD%A6%E4%B9%A06-%E7%94%9F%E6%88%90%E5%8F%AF%E6%8E%A7%E6%80%A7/" title="Diffusionå­¦ä¹ 6-ç”Ÿæˆå¯æ§æ€§"><span class="has-text-weight-semibold">Next: Diffusionå­¦ä¹ 6-ç”Ÿæˆå¯æ§æ€§</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="qzq2514/qzq2514.github.io" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com/qzq2514"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/qzq2514"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com/qzq2514"><i class="iconfont icon-ins"></i></a><!-- publish--><a title="publish" target="_blank" rel="noopener nofollow" href="https://blog.csdn.net/qzq2514"><i class="iconfont icon-rss"></i></a><!-- RSS--><!-- çŸ¥ä¹--><a title="zhihu" target="_blank" rel="noopener nofollow" href="//zhihu.com/people/qi-zhong-qi-62"><i class="iconfont icon-zhihu"></i></a><!-- é¢†è‹±--><!-- è„¸ä¹¦--></section><p><span>Copyright Â©</span><span> Georgeqi 2025</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>