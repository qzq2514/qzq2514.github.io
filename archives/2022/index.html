<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>Georgeqi's Blog</title><meta name="description" content="The harder you work, the luckier you will be~"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Georgeqi_Blog" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Georgeqi's Blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>Archives · 2022</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/2022/12/31/Diffusion%E5%AD%A6%E4%B9%A04-%E6%95%88%E6%9E%9C%E5%92%8C%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87/ImprovedDDPM_figure3.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2022/12/31/Diffusion%E5%AD%A6%E4%B9%A04-%E6%95%88%E6%9E%9C%E5%92%8C%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87/"><img class="post-cover-img js-img-fadeIn" src="/2022/12/31/Diffusion%E5%AD%A6%E4%B9%A04-%E6%95%88%E6%9E%9C%E5%92%8C%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87/ImprovedDDPM_figure3.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Diffusion"><i class="tag post-item-tag">Diffusion</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2022/12/31/Diffusion%E5%AD%A6%E4%B9%A04-%E6%95%88%E6%9E%9C%E5%92%8C%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87/">Diffusion学习4-效果和性能提升</a></h2><time class="has-text-grey" datetime="2022-12-31T14:10:22.000Z">2022-12-31</time><p class="is-flex-grow-2 mt-2">下述效果的具体代码见: qzq2514/Diffusion
效果提升
这里简单实验和讨论了在训练DDPM过程中使用的损失函数(L1或L2损失)，并且实验了Improved DDPM 中提到的Cosine Beta Schedule带来的效果提升。
Cosine Beta Schedule
首先回顾下DDPM在前向过程中的一个重要公式-利用重采样技巧从直接得到，即Diffusion学习2-理论推导中的公式(3):  而且在原DDPM论文中使用的线性Beta采样，即:
torch.linspace(start=0.0001, end=0.02, steps=100)
Improved DDPM则进一步分析了这种Beta设计的缺点，取出论文中的图3和图5:



Linear和Cosine的Beta方式对于加噪的..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2022/12/31/Diffusion%E5%AD%A6%E4%B9%A04-%E6%95%88%E6%9E%9C%E5%92%8C%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221228191848_StyleGAN_face_size128_225_progress.jpg" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/"><img class="post-cover-img js-img-fadeIn" src="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/20221228191848_StyleGAN_face_size128_225_progress.jpg" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Diffusion"><i class="tag post-item-tag">Diffusion</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/">Diffusion学习3-代码实践</a></h2><time class="has-text-grey" datetime="2022-12-25T13:27:59.000Z">2022-12-25</time><p class="is-flex-grow-2 mt-2">先放一张在人脸数据集上训练好后去噪的可视化过程

DDPM可视化去噪

各数据集参数配置及效果
训练:
CUDA_VISIBLE_DEVICES=0 python train_solver.py --data_name &quot;Flower102&quot;
在config.yaml中各个数据集使用默认的Training Setting，每个数据集特有的配置见config.yaml下的Train_Data.
生成效果
生成效果如下:



数据集
去噪过程可视化
最终去噪效果
插值




Mnist





Fashion_Mnist





Cifar10





Flower102





StyleGAN2人脸






上述训练数据集和已经训练好的模型放在这里.

去噪过程可视化中，如果在采样step内..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2022/12/25/Diffusion%E5%AD%A6%E4%B9%A03-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/2022/12/20/Diffusion%E5%AD%A6%E4%B9%A02-%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC/各种生成模型总览.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2022/12/20/Diffusion%E5%AD%A6%E4%B9%A02-%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC/"><img class="post-cover-img js-img-fadeIn" src="/2022/12/20/Diffusion%E5%AD%A6%E4%B9%A02-%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC/各种生成模型总览.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Diffusion"><i class="tag post-item-tag">Diffusion</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2022/12/20/Diffusion%E5%AD%A6%E4%B9%A02-%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC/">Diffusion学习2-理论推导</a></h2><time class="has-text-grey" datetime="2022-12-20T13:27:59.000Z">2022-12-20</time><p class="is-flex-grow-2 mt-2">概述

生成模型总览(原图来自lilianweng.blog)

Diffusion属于生成模型的一种，相比较于GAN等其他生成模型，Diffusion模型最大的不同之处就在于其latent code是和原输入图相同尺寸的。Diffusion模型其实也可以看成是一个隐变量模型，并且与VAE,GAN的单隐变量不同，其可以看成存在多个隐变量(即加噪过程中的每个加噪结果都可以看成一个隐变量)。Diffusion模型总体包括前向加噪和逆向去噪两个过程:

前向过程-加噪扩散:对给定的真实图像不断添加高斯噪声，经过中间状态最终变成纯高斯噪声
逆向过程-去噪生成:从完全的纯噪声不断去噪，经过中间状态最终变成其对应的真实图像

上面两个过程示意图可以表示如下:

Diffusion的前向和逆向过程(原图来自Ho et a..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2022/12/20/Diffusion%E5%AD%A6%E4%B9%A02-%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/2022/12/10/Diffusion%E5%AD%A6%E4%B9%A01-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/VAE示意图.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2022/12/10/Diffusion%E5%AD%A6%E4%B9%A01-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"><img class="post-cover-img js-img-fadeIn" src="/2022/12/10/Diffusion%E5%AD%A6%E4%B9%A01-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/VAE示意图.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Diffusion"><i class="tag post-item-tag">Diffusion</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2022/12/10/Diffusion%E5%AD%A6%E4%B9%A01-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/">Diffusion学习1-预备知识</a></h2><time class="has-text-grey" datetime="2022-12-10T13:27:59.000Z">2022-12-10</time><p class="is-flex-grow-2 mt-2">Diffusion模型打响了AIGC的第一枪，我之前一直是做GAN这一块的图像生成，但是奈何Diffuison模型效果好的离谱，也趁着空闲时间抱着学习的态度看看到底是他是靠着什么&quot;吊打&quot;GAN的，但是在推Diffusion公式的时候，牵扯到很多比较细碎的小知识点，有一些因为不常用也都忘记了，这里正好补充在这里，方便后续快速查询。 关于Diffusion相关的论文推导后面会单独开一个新的文章进行介绍，如果有时间和精力应该还会补充代码的实践~
马尔科夫链

总体思想: 过去的所有信息都被保存在了现在的状态中，只使用现在状态就能预测到之后的状态，换句话说就是某个时刻的状态转移概率只依赖于它的前一个状态。
公式化表达:
举例:

股市涨跌：当前股市的涨、跌、平的状态概率分别为[0.3,0.4,0.3]，且转移概率矩..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2022/12/10/Diffusion%E5%AD%A6%E4%B9%A01-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/">Read more</a></section></article></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container archives-widget is-in-archive-page"><h3>Archives</h3><section><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/12/">December 2022</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">1</span></li></ul></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com/qzq2514"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/qzq2514"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com/qzq2514"><i class="iconfont icon-ins"></i></a><!-- publish--><a title="publish" target="_blank" rel="noopener nofollow" href="https://blog.csdn.net/qzq2514"><i class="iconfont icon-rss"></i></a><!-- RSS--><!-- 知乎--><a title="zhihu" target="_blank" rel="noopener nofollow" href="//zhihu.com/people/qi-zhong-qi-62"><i class="iconfont icon-zhihu"></i></a><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> Georgeqi 2023</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>